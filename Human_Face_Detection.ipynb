{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyoof9HGVvDfkVqVrrGC59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChetanAIML/Capstone/blob/main/Human_Face_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTdJdG5qacIo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "# Step 1: Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Load the CSV file containing facial bounding box coordinates\n",
        "df = pd.read_csv('facial_bounding_boxes.csv')\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Descriptive statistics of bounding box coordinates\n",
        "print(df.describe())\n",
        "\n",
        "# Visualize the distribution of bounding box coordinates\n",
        "plt.hist(df['x0'], bins=20, edgecolor='black')\n",
        "plt.title('Distribution of x0 coordinates')\n",
        "plt.show()\n",
        "\n",
        "# Visualize images with bounding boxes\n",
        "for i in range(10):\n",
        "    image_path = df.loc[i, 'image_path']\n",
        "    image = plt.imread(image_path)\n",
        "    x0, y0, x1, y1 = df.loc[i, ['x0', 'y0', 'x1', 'y1']]\n",
        "    plt.imshow(image)\n",
        "    plt.plot([x0, x1], [y0, y0], 'b-', linewidth=2)\n",
        "    plt.plot([x0, x0], [y0, y1], 'b-', linewidth=2)\n",
        "    plt.plot([x1, x1], [y0, y1], 'b-', linewidth=2)\n",
        "    plt.plot([x0, x1], [y1, y1], 'b-', linewidth=2)\n",
        "    plt.show()\n",
        "\n",
        "# Step 2: Split Dataset into Train, Test, and Validation Sets\n",
        "\n",
        "# Divide the data into training, testing, and validation sets\n",
        "train_data = df.sample(frac=0.7)\n",
        "test_data = df.drop(train_data.index)\n",
        "val_data = test_data.sample(frac=0.25)\n",
        "test_data = test_data.drop(val_data.index)\n",
        "\n",
        "# Step 3: Train, Evaluate, and Plot Accuracy and Loss\n",
        "\n",
        "# Define the CNN architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(4, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_dataframe(train_data, target_size=(224, 224), batch_size=32, class_mode='rectangles')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, validation_data=val_data)\n",
        "\n",
        "# Plot accuracy and loss curves\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Face Detection and Bounding Box Drawing\n",
        "\n",
        "# Load the image to detect faces in\n",
        "image = plt.imread('test_image.jpg')\n",
        "\n",
        "# Preprocess the image\n",
        "image = tf.image.resize(image, (224, 224))\n",
        "image = image.astype('float32') / 255.0\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "\n",
        "# Draw bounding boxes on the image\n",
        "for prediction in predictions:\n",
        "    x0, y0, x1, y1 = prediction\n",
        "    x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
        "    plt.plot([x0, x1], [y0, y0], 'b-', linewidth=2)\n",
        "    plt.plot([x0, x0], [y0, y1], 'b-', linewidth=2)\n",
        "    plt.plot([x1, x1], [y0, y1], 'b-', linewidth=2)\n",
        "    plt.plot([x0, x1], [y1, y1], 'b-', linewidth=2)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n"
      ]
    }
  ]
}